- 어려운건 없으세요. 열심히 달리면 되시는지. 첫 번째 질문할게요. 크롤링 하는 사이트가 많더라구요. 잘 되고 계시나요

다 된 상태입니다. 그 csv랑 이미지랑 크롤링해와서 처리하면 되는 단계입니다. 데이터들 만들고 학습할거 학습시키고, 기능들은 다 각자 맡아서 만들고 있는데, 만들고 나서 이거를 서버 db 연결하면서 웹에 보여주는 것은 아직까지 그 단계까지 어떻게 해야할지가 궁금합니ㅏㄷ.

- 그렇다면 지금 데이터는 모아놨는데, csv파일로 모아놨는데, db로 모으는 걸로. 모델학습자체는 파일로 해도 상관없을 것 같아요. 텍스트파일은 사이즈가 크지가 않아요. 크롤링도 사이즈가 큰거 같지 ㅇ낳더라구요. 모으는 출처별로 csvㄹ파일로 만들어놓고 로드해서 학습하는건 괜찮아요.
학습시킬 때 보니까, 형태소 분석기를 써서 tfidf로 돌리신 거잖아요? 형태소 분석기 명사 동사만 활용하시나요? 아니면?

형태소 분석기를 사용하지 않고, tfidf를 기사 본문이랑 제목을 통째로 tfidf를 돌렸습니다.

- 그럼 형태소 분석기를 썼으면 조사같은건 걸러서 쓰는게 성능이 더 잘나올거 같아요. 해보시면 알 것 같고. 형태소 분석기를 안쓰고 word2vec같은 imbedd같은 걸 쓰는 걸 추천드려요.
tfidf를 쓴다는 것은 기존에 countvectorizer단어 빈도수를 맞춰서 onehot인코딩을 하는, 자주 등장하는 단어에 가중치를 주는 것이 그 방식이거든요. 자주 나오는 단어에 점수를 주겠다. 이런 느낌.
on off식으로 하다보니까 그런식에서 가중치를 주겠다 이건데. 단어 사이에 유사도같은게 반영이 안돼요. 이런걸 반영해주는게 word2vec. 이거 뿐만아니라 
가장 유명한게 워드 투벡이고. 이걸 사용하면 단어간 유사도를 측정할 수 있습니다. 단어 토크나이저가 등장하는데, 딥러닝 계열의. 여기선 동음이의어 처리가 안되는데 딥러닝 모델쪽부터 동음이의어 처리가 돼요. 약간 의미가 애매해지는게 생길 수 있는데 딥러닝 계열은, context문맥을 보고 만들기 때문에 좀 더 정확한 임베딩을 만들 수 있다.
머신러닝 에서는 word2vec을 쓰는걸 추천드립니다. tfidf를 단어가 많아질수록 차원이 점점 늘어나는데, word2vec을 사용하면 고정길이의 임베딩 vector가 나오기 때문에. 차원이 하나 늘어날 수록 촘촘히 표현 할 수 있다보니 그런 장점이 있기 때문에 추천한다
그 다음으로는 feature로는 어떤걸 활용하세요?

그건 logisticregression과 lda를 사용합니다. 

- 가장 기본적이고 시작하기 좋은 모델인건 맞습니다. 다른 모델들도 활용해보시구요. 특히 앙상블 모델을 활용해보시면, 여러 머신러닝모델을 사용한 것을 보여주기 때문에 이용을 꼭 해보시고, 성능비교를 해서 어떤 모델이 더 좋은건지 찾아가는 과정이 필요하다.
최근엔 auto ~~ 라고 어떤 모델을 선택해서 앙상블할지 알려주는 lib가 있으니 그걸 활용해보시는 게 의미가 있다고 생각합니다. 일단 활용해보시고, 앙상블 모델 적용 해보시고, 추가적으로 auto ml 파이킷? 런 라이브러리를 사용하면 모델 자체도 추천해주는 모델을 쓸 수 있습니다. 랜덤 포레스트 40% 선형회귀 20% 자기가 조합과 비율을 조정해요. 튜닝을 해주기 때문에. 모델 튜닝에 드는 시간과 자원을 상당히 아낄 수 있어요. 이걸 다른데 사용해서 프로젝트 완성도를 높일 수 있다.
그럼 하고 계시는 프로젝트가 키워드 추출. 보여주는 거다 보니까 feature는 텍스트 위주. feature를 추가적으로 활용할 수 있는 것은 다른 프로젝트에 비해서 크게 없어보여요. 지금으로도 괜찮아 보이구요
가장 중요한 거. 성능 지표를 어떤걸 사용할지?

정해진 게 없습니다.

- 분류가 제대로 됐는지 안됐는지 알 수가 없기 때문에 성능 지표를 가지고 가야해요. 그걸 추천 드린다면, 어떻게 해야할지가 좀 애매하긴 한데. 이거부터 질문 드릴게요. 선형회귀 모델의 결과가 어떤걸 얻는거에요? output이?

기사의 긍정부정을 분류할 때요.

긍정부정을 어떻게 아나요?

라벨링을 통해서요

라벨링은 직접해서요?

라벨링 직접 몇 개 정도 하셨어요?

2000개

- 갯수가 더 많아야 해요. 적어도 10000개는 있어야 해요. 데이터 셈플링 작업을 늘리는 작업부터 해야해요. 모델의 퍼포먼스 비교는 후순위구요. 이제 샘플 수만 늘려서 작업하는 건 어렵지 않잖아요? 한 쪽에서는 샘플늘리는 작업하시고, 모델을 여러개 전개하면서 개별적으로 성능지표. 그러니까 성능지표는 긍정 라벨링된 기사를 넣었을 때 긍정이 나와야 하는 그런 성능이 나와야 하잔하용? f1-score가 일반적이에요.
이 점수를 통해서 어느정도가 나왔는지. 그래야 여러 모델을 비교를 할 때 성능 수치를 얘기를 해야 하거든요. 그거를 보여줘야하기 때문에 그걸 추천드리고. 
나온 걸 보니까, 프로젝트 자체가 좀 더 서비스적에 많이 맞춰진 것 같아요. 그래서 좀 더 프론트 엔드 기능이 더 중요한 프로젝트 일 수도 있겠따라는 생각이 들어요. 잘 모르겠지만
그냥 분류했다 라고만 하기에는 임팩트가 약하니. 어떻게 보여줄 것인지. 프론트나 백의 경험이 있으신가요? 어려움이 있으신가요?

저희 대부분이 경험 상태라서요. 프론트 에서도 맡았을 때 이렇게 하면 되지 않을까. 기능 구현만 해놓고 나중에 팀원들과 이거를 이렇게 만들었는데 발전시키려면 어떻게 해야할 까 조금씩 발전시키려는 생각을 가지고 있었어요,

- 큰 틀은 잡아야 해요. 프론트 하시는 분이 어디에 어떤 컴포넌트 들어갈지를 분류하시고, 프론트 한 분이신가요?

프론트는 사실상 1명입니다. 현재 한 명이 카카오맵하고 있어서

- 각각 페이지별로 들어가는 컴포넌트 별로 개발해서, 컴포넌트 리액트에 붙이는게 가장 기본적인 방법이에요. 컴포넌트 베이스 개발이라고 하거든요. 컴포넌트 잘 설계하는게 필요하고, 잘 묶어서 인덱스에서 인풋해서 보여주는 걸로.
싱글페이지로 하시나요 대시보드로 하시나요?

배운게 리액트라서 아마 싱글페이지 인 듯 합

- 아마 리액트 하시면서 처음 하시니까 기본적으로 리액트에서 컴포넌트 개발, 2번째 라우팅 어떻게 하는지 3번째 리덕스나 스트리 매니지 해주는 리코일 같은 라이브러리 등을 활용해서 전역적인 상태를 관리해주는. 상태 관리하는 기능. 총 세가지정도는 기본적으로 알고 있어야 리액트 해봤다고 말할 수 있어요. 이걸 못한다면 리액트 해봤다고 말하기 민망한 수준이거든요. 이걸 다 이용해서 개발하는 것을 로그로 잡고 해주시는게 중요해요. 백엔드 쪽이 없으신가봐요?

파이어베이스를 일단 배우고 있는데

- 백엔드 하시는 분은 db쪽은 다룰 줄 알아야 하는게 중요한 것 같아요. flask같은 프레임 워크가 중요한게 아니고, 백엔드에서 도와주는 부분이 너무 많다보니까 라우팅 관련해서 연결하는 것은 당연히 제공하는 기능을 사용해야 하지만, db와 interactive할 때 통신할 때 있어서 orm으로 만들어서 테이블에 들어가는 컬럼과 클래스랑 매핑해서 오브젝트 형태로 변환하는 것. 오브젝트 형태가 json으로 변환되서 api로 나가는 거에 초점을 맞추면 될 것 같고. 
그것부터 정의를 해야죠 프론트랑 백엔드랑 통신할 때 어떤 규격으로 통신할 건지. 그거에 맞춰서 데이터를 넣어주려면, db테이블을 어떻게 설계해야 할건지. 어떤 columns를 담아야할건지, 예를 들어 string이다 하면 몇 글자 까지 넣을 건지. 넘으면 예외처리를 어떻게 할건지 신경써서 프로젝트 하시면 될 것 같아요 
프로젝트 난이도는 그렇게 크게 높아서 하다가 못하겠어요. 정도는 아니고, 기본적인 기능을 배워간다에 대해 초점을 맞춰서 하면 될 것 같아요. 